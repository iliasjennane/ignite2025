{"cells":[{"cell_type":"markdown","source":["# AutoCouncil — Fabric Synthetic Data Generator (PySpark)\n","\n","Generates large-scale synthetic automotive datasets for the AutoCouncil scenario: dealers, models, customers, incentives, inventory, and sales fact data with campaign + logistics anomalies.\n","\n","## Features\n","- 38M+ rows across 6 Delta tables\n","- Azure Motors EV SUV campaign uplift (Jun–Sep 2025)\n","- West/Pacific NW logistics delay (Aug–Sep 2025)\n","- Deterministic randomness (seed + hash)\n","- Fabric-ready (relative lakehouse paths)\n","\n","## Run Steps\n","1. Attach & pin your Lakehouse\n","2. Run cells top → bottom\n","3. Inspect Tables and Files/reports\n","\n","Estimated runtime: 10–20 minutes"],"metadata":{},"id":"8a1f7797"},{"cell_type":"markdown","source":["## 1. Test Lakehouse Connectivity\n","Ensures we can read/write to the attached Lakehouse.\n","Prerequisites: Lakehouse attached + write permissions"],"metadata":{},"id":"a8990982"},{"cell_type":"code","source":["import os, pandas as pd\n","tables_path = 'Tables'\n","files_path = 'Files'\n","print('📋 Fabric environment detected')\n","print('🔌 Testing Lakehouse connectivity...')\n","try:\n","    os.makedirs(tables_path, exist_ok=True)\n","    os.makedirs(files_path, exist_ok=True)\n","    test_path = f'{files_path}/.connectivity_test'\n","    with open(test_path,'w') as f: \n","        f.write(f'Test at {pd.Timestamp.now()}')\n","    with open(test_path,'r') as f: \n","        _ = f.read()\n","    print('✅ Lakehouse connectivity OK')\n","except Exception as e:\n","    print(f'❌ Connectivity failed: {e}')\n","    raise"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:11:40.9752641Z","session_start_time":"2025-10-17T20:11:40.9763057Z","execution_start_time":"2025-10-17T20:11:54.1333736Z","execution_finish_time":"2025-10-17T20:11:58.7494159Z","parent_msg_id":"26a665a3-9873-4b97-8793-28865904a540"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["📋 Fabric environment detected\n🔌 Testing Lakehouse connectivity...\n✅ Lakehouse connectivity OK\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"26e32d32"},{"cell_type":"markdown","source":["## 2. Install Required Libraries\n","Uses Faker for realistic synthetic attributes."],"metadata":{},"id":"1a4d4bd5"},{"cell_type":"code","source":["%pip install faker\n","print('✅ Faker installed')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[4,5,6,7,8,9],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:15:31.7225927Z","session_start_time":null,"execution_start_time":"2025-10-17T20:15:31.7246194Z","execution_finish_time":"2025-10-17T20:15:54.8165211Z","parent_msg_id":"6d4f2f41-e358-4bf5-ab07-8828f93ab8f3"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting faker\n  Downloading faker-37.11.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: tzdata in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from faker) (2023.3)\nDownloading faker-37.11.0-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: faker\nSuccessfully installed faker-37.11.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n✅ Faker installed\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7e46cb47"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from faker import Faker\n","import random, hashlib\n","from datetime import datetime, timedelta\n","Faker.seed(12345); random.seed(12345); faker = Faker()\n","try: spark; print('✅ Using existing Spark session')\n","except NameError: \n","    spark = SparkSession.builder.appName('AutoCouncil Data Generator')\\\n","        .config('spark.sql.extensions','io.delta.sql.DeltaSparkSessionExtension')\\\n","        .config('spark.sql.catalog.spark_catalog','org.apache.spark.sql.delta.catalog.DeltaCatalog')\\\n","        .getOrCreate(); print('✅ Created Spark session')\n","print('Spark version:', spark.version)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:20:43.4494901Z","session_start_time":null,"execution_start_time":"2025-10-17T20:20:48.1169062Z","execution_finish_time":"2025-10-17T20:20:48.9390417Z","parent_msg_id":"36108dda-2ca6-4042-b369-6dc004c3e908"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 11, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Using existing Spark session\nSpark version: 3.5.1.5.4.20251001.1\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e29f2bfa"},{"cell_type":"markdown","source":["## 3. Configuration\n","Scale + scenario setup"],"metadata":{},"id":"b638b837"},{"cell_type":"code","source":["NUM_DEALERS = 1200\n","NUM_MODELS = 600\n","NUM_CUSTOMERS = 1_000_000\n","SALES_TARGET_ROWS = 20_000_000\n","MONTHS = [f'{y}-{m:02d}' for y in [2024,2025] for m in range(1,13)]\n","REGIONS = ['Northeast','Mid-Atlantic','Midwest','South','Mountain','West','Pacific NW','Southwest']\n","ANOMALY_MONTHS = ['2025-06','2025-07','2025-08','2025-09']\n","ANOMALY_BRAND = 'Azure Motors'\n","ANOMALY_BODYTYPE = 'EV SUV'\n","TABLES_PATH='Tables'; FILES_PATH='Files'\n","print('✅ Config loaded'); print('Months:', len(MONTHS),'Regions:',len(REGIONS))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:20:54.0293978Z","session_start_time":null,"execution_start_time":"2025-10-17T20:20:54.0306499Z","execution_finish_time":"2025-10-17T20:20:54.3524593Z","parent_msg_id":"fed7fa2b-9a45-481a-bc7c-c79edc9b146b"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 12, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Config loaded\nMonths: 24 Regions: 8\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0c7b186b"},{"cell_type":"markdown","source":["## 4. Helper Functions"],"metadata":{},"id":"9b6108fa"},{"cell_type":"code","source":["def hash_random(*items):\n","    hv = int(hashlib.md5('|'.join(map(str,items)).encode()).hexdigest(),16)\n","    return (hv % 1_000_000) / 1_000_000.0\n","def write_delta(df,name,mode='overwrite'):\n","    path=f'{TABLES_PATH}/{name}'\n","    df.write.format('delta').mode(mode).save(path)\n","    print(f'   ✅ {name}: {df.count():,} rows')\n","    return path\n","print('✅ Helpers ready')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:25:38.8486275Z","session_start_time":null,"execution_start_time":"2025-10-17T20:25:38.8497023Z","execution_finish_time":"2025-10-17T20:25:39.133443Z","parent_msg_id":"100f1472-24c7-4230-b701-18b2aba7b1e7"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 13, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Helpers ready\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"56cff44a"},{"cell_type":"markdown","source":["## 5. Vehicle Models"],"metadata":{},"id":"c3e90437"},{"cell_type":"code","source":["body_types = ['Sedan','Hatchback','SUV','EV Sedan','EV SUV','Pickup','Van','Coupe','Wagon','Crossover']\n","brands=[ANOMALY_BRAND]\n","while len(brands)<40:\n","    b=f'{faker.company()} Motors'.replace(',','')\n","    if b not in brands:\n","        brands.append(b)\n","\n","models=[]\n","# First, ensure Azure Motors has EV SUV models (critical for campaign)\n","for i in range(60):  # 60 Azure Motors EV SUV models\n","    trim=f'{faker.color_name()} {(i%18)+1}'\n","    models.append({\n","        'model_id':f'M{i:05d}',\n","        'brand':ANOMALY_BRAND,\n","        'model_name':f\"{ANOMALY_BRAND.split()[0]} {ANOMALY_BODYTYPE} {trim}\",\n","        'body_type':ANOMALY_BODYTYPE,\n","        'msrp':21000+(i%120)*600,\n","        'launch_date':'2024-01-01'\n","    })\n","# Fill remaining models with varied brands/body types\n","for i in range(60, NUM_MODELS):\n","    brand=brands[i%len(brands)]\n","    btype=body_types[i%len(body_types)]\n","    trim=f'{faker.color_name()} {(i%18)+1}'\n","    models.append({\n","        'model_id':f'M{i:05d}',\n","        'brand':brand,\n","        'model_name':f\"{brand.split()[0]} {btype} {trim}\",\n","        'body_type':btype,\n","        'msrp':21000+(i%120)*600,\n","        'launch_date':'2024-01-01'\n","    })\n","\n","models_df=spark.createDataFrame(models)\n","write_delta(models_df,'models')\n","print(f'✅ Models created: {len(models)} across {len(brands)} brands (including {60} Azure Motors EV SUV models)')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:30:23.8228474Z","session_start_time":null,"execution_start_time":"2025-10-17T20:30:23.8239224Z","execution_finish_time":"2025-10-17T20:30:31.6271271Z","parent_msg_id":"744b0fab-0dee-4a66-a305-540aca81bbfe"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 15, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   ✅ models: 600 rows\n✅ Models created: 600 across 40 brands (including 60 Azure Motors EV SUV models)\n"]}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c6f69c2a"},{"cell_type":"markdown","source":["## 6. Dealers"],"metadata":{},"id":"949570d8"},{"cell_type":"code","source":["dealer_types=['Auto','Motors','Cars','Dealers','Group']\n","dealers=[]\n","for i in range(NUM_DEALERS):\n","    region=REGIONS[i%len(REGIONS)]\n","    city=faker.city()\n","    dtype=random.choice(dealer_types)\n","    dealers.append({'dealer_id':f'D{i:05d}','dealer_name':f'{city} {dtype}','region':region,'lat':25.0+(i%30)*0.9,'lon':-124.0+(i%60)*1.2})\n","dealers_df=spark.createDataFrame(dealers); write_delta(dealers_df,'dealers')\n","print(f'✅ Dealers created: {len(dealers)}')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:33:51.6522499Z","session_start_time":null,"execution_start_time":"2025-10-17T20:33:51.6532658Z","execution_finish_time":"2025-10-17T20:33:55.0617407Z","parent_msg_id":"fda6ea1b-0c35-49d5-a6fa-84bd26cfac56"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 16, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   ✅ dealers: 1,200 rows\n✅ Dealers created: 1200\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a63ffd4f"},{"cell_type":"markdown","source":["## 7. Customers (1M)\n","Progress prints every 100K."],"metadata":{},"id":"dcd1791e"},{"cell_type":"code","source":["customers=[]\n","for i in range(NUM_CUSTOMERS):\n","    first=faker.first_name(); last=faker.last_name()\n","    customers.append({'customer_id':f'C{i:07d}','first_name':first,'last_name':last,'email':faker.email().lower().replace(' ','.'),'age':21+(i%60),'annual_income':35000+(i%120)*1200+(i%7)*900})\n","    if i and i%100000==0: print(f'   {i:,} customers...')\n","customers_df=spark.createDataFrame(customers); write_delta(customers_df,'customers')\n","print(f'✅ Customers created: {len(customers):,}')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[17],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:33:56.53872Z","session_start_time":null,"execution_start_time":"2025-10-17T20:33:56.5399056Z","execution_finish_time":"2025-10-17T20:37:54.8638187Z","parent_msg_id":"281912f1-6092-44eb-be2c-9c7fcec166e5"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 17, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   100,000 customers...\n   200,000 customers...\n   300,000 customers...\n   400,000 customers...\n   500,000 customers...\n   600,000 customers...\n   700,000 customers...\n   800,000 customers...\n   900,000 customers...\n   ✅ customers: 1,000,000 rows\n✅ Customers created: 1,000,000\n"]}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1691ecf2"},{"cell_type":"markdown","source":["## 8. Incentives & Campaign"],"metadata":{},"id":"c8150102"},{"cell_type":"code","source":["incentives=[]\n","for brand in brands:\n","  for bt in body_types:\n","    for m in MONTHS:\n","      base_rebate=int(hash_random(brand,bt,m)*3500); base_apr=(hash_random(brand,m)*5.0)+0.9\n","      rebate=base_rebate; apr=base_apr\n","      if brand==ANOMALY_BRAND and bt==ANOMALY_BODYTYPE and m in ANOMALY_MONTHS:\n","        rebate+=3000; apr=1.9\n","      incentives.append({'brand':brand,'body_type':bt,'month':m,'rebate':rebate,'apr':apr})\n","incentives_df=spark.createDataFrame(incentives); write_delta(incentives_df,'incentives')\n","print(f'✅ Incentives rows: {len(incentives):,}')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":18,"statement_ids":[18],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:39:43.5189289Z","session_start_time":null,"execution_start_time":"2025-10-17T20:39:43.520189Z","execution_finish_time":"2025-10-17T20:39:45.8896768Z","parent_msg_id":"ebff1be7-1917-4e57-aa97-edf915d80b66"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 18, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   ✅ incentives: 9,600 rows\n✅ Incentives rows: 9,600\n"]}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c0ae4e58"},{"cell_type":"markdown","source":["## 9. Inventory (~17M+)\n","Includes regional logistics constraint (incoming *0.7 West/Pacific NW Aug–Sep 2025)"],"metadata":{},"id":"c6d04d12"},{"cell_type":"code","source":["inventory=[]; count=0\n","for d in dealers:\n","  for m in models:\n","    for month in MONTHS:\n","      on_hand=80+int(hash_random(d['dealer_id'],m['model_id'],month)*80)\n","      incoming=10+int(hash_random(m['model_id'],month)*40)\n","      turn=(hash_random(d['dealer_id'],m['model_id'])*4.0)+0.8\n","      if d['region'] in ['West','Pacific NW'] and month in ['2025-08','2025-09']: incoming=int(incoming*0.7)\n","      inventory.append({'dealer_id':d['dealer_id'],'region':d['region'],'model_id':m['model_id'],'brand':m['brand'],'body_type':m['body_type'],'month':month,'on_hand':on_hand,'incoming':incoming,'turn_rate':turn})\n","      count+=1\n","      if count and count%1_000_000==0: print(f'   {count:,} inventory rows')\n","inventory_df=spark.createDataFrame(inventory); write_delta(inventory_df,'inventory')\n","print(f'✅ Inventory rows: {len(inventory):,}')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":19,"statement_ids":[19],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:40:42.0543747Z","session_start_time":null,"execution_start_time":"2025-10-17T20:40:42.0554477Z","execution_finish_time":"2025-10-17T20:51:08.5824713Z","parent_msg_id":"c181168b-b254-4175-a2f6-64e0a80bc192"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 19, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   1,000,000 inventory rows\n   2,000,000 inventory rows\n   3,000,000 inventory rows\n   4,000,000 inventory rows\n   5,000,000 inventory rows\n   6,000,000 inventory rows\n   7,000,000 inventory rows\n   8,000,000 inventory rows\n   9,000,000 inventory rows\n   10,000,000 inventory rows\n   11,000,000 inventory rows\n   12,000,000 inventory rows\n   13,000,000 inventory rows\n   14,000,000 inventory rows\n   15,000,000 inventory rows\n   16,000,000 inventory rows\n   17,000,000 inventory rows\n   ✅ inventory: 17,280,000 rows\n✅ Inventory rows: 17,280,000\n"]}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2815897d"},{"cell_type":"markdown","source":["## 10. Sales Transactions (20M)\n","Campaign boost: Azure Motors EV SUV units *1.35 in campaign months"],"metadata":{},"id":"458f2230"},{"cell_type":"code","source":["# BATCHED Sales Transactions Generation (avoids huge driver list)\n","from builtins import max\n","inc_lookup={(i['brand'],i['body_type'],i['month']):i for i in incentives}\n","per_combo=NUM_DEALERS*NUM_MODELS*len(MONTHS)\n","repeat=max(1,int((SALES_TARGET_ROWS/per_combo)+0.5))\n","TARGET=SALES_TARGET_ROWS\n","BATCH_SIZE=250_000  # tune if needed\n","sc=0\n","batch=[]\n","first_write=True\n","import math\n","def flush(batch_rows, first):\n","    if not batch_rows: return first\n","    df=spark.createDataFrame(batch_rows)\n","    mode='overwrite' if first else 'append'\n","    write_delta(df,'car_sales',mode=mode)\n","    return False\n","for d in dealers:\n","  for m in models:\n","    for month in MONTHS:\n","      for r in range(repeat):\n","        if sc>=TARGET: break\n","        rep=str(r)\n","        inc=inc_lookup.get((m['brand'],m['body_type'],month),{})\n","        units=1+int(hash_random(d['dealer_id'],m['model_id'],rep)*4)\n","        discount=int(hash_random(d['dealer_id'],m['model_id'],month)*2000)\n","        day=1+int(hash_random(d['dealer_id'],m['model_id'],rep)*28)\n","        year,mo=month.split('-'); sale_date=f'{year}-{mo}-{day:02d}'\n","        cust=customers[int(hash_random(d['dealer_id'], m['model_id'], rep) * len(customers))]['customer_id']\n","        if m['brand']==ANOMALY_BRAND and m['body_type']==ANOMALY_BODYTYPE and month in ANOMALY_MONTHS: units=int(units*1.35)\n","        final_price=m['msrp']-discount - (inc.get('rebate',0)*0.7)\n","        cogs=m['msrp']*(0.76+hash_random(m['model_id'],d['dealer_id'])*0.1)\n","        revenue=final_price*units; profit=revenue-(cogs*units)\n","        batch.append({'sale_id':f'S{sc:08d}','dealer_id':d['dealer_id'],'region':d['region'],'model_id':m['model_id'],'brand':m['brand'],'body_type':m['body_type'],'model_name':m['model_name'],'month':month,'sale_date':sale_date,'customer_id':cust,'units':units,'msrp':m['msrp'],'discount':discount,'rebate':inc.get('rebate',0),'apr':inc.get('apr',0.0),'final_price':final_price,'cogs':cogs,'revenue':revenue,'profit':profit})\n","        sc+=1\n","        if sc % 1_000_000 == 0: print(f'   {sc:,} sales rows (cumulative)')\n","        if len(batch) >= BATCH_SIZE:\n","            first_write=flush(batch, first_write)\n","            batch=[]\n","      if sc>=TARGET: break\n","    if sc>=TARGET: break\n","  if sc>=TARGET: break\n","# flush remaining\n","first_write=flush(batch, first_write)\n","print(f'✅ Sales rows written: {sc:,}')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":20,"statement_ids":[20],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T20:51:15.5043048Z","session_start_time":null,"execution_start_time":"2025-10-17T20:51:15.505496Z","execution_finish_time":"2025-10-17T21:14:40.1241638Z","parent_msg_id":"07085242-cea0-4c28-b01a-212090268262"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 20, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   1,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   2,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   3,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   4,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   5,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   6,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   7,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   8,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   9,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   10,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   11,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   12,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   13,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   14,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   15,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   16,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   17,000,000 sales rows (cumulative)\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 250,000 rows\n   ✅ car_sales: 30,000 rows\n✅ Sales rows written: 17,280,000\n"]}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6f1d3f79"},{"cell_type":"markdown","source":["## 11. Example Analytic Questions & Queries\n","This section provides sample business questions you can answer with the generated data, along with SQL queries to run in Microsoft Fabric."],"metadata":{},"id":"44b1f854"},{"cell_type":"code","source":["# Register Delta tables as temporary views for SQL queries\n","tables = ['models', 'dealers', 'customers', 'incentives', 'inventory', 'car_sales']\n","for table in tables:\n","    try:\n","        df = spark.read.format('delta').load(f'Tables/{table}')\n","        df.createOrReplaceTempView(table)\n","        print(f'✅ Registered view: {table}')\n","    except Exception as e:\n","        print(f'❌ Failed to register {table}: {e}')\n","print('✅ All tables registered for SQL queries')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":21,"statement_ids":[21],"state":"finished","livy_statement_state":"available","session_id":"4825afcd-6c6c-4c32-a606-a141b2984f0a","normalized_state":"finished","queued_time":"2025-10-17T21:01:49.4163271Z","session_start_time":null,"execution_start_time":"2025-10-17T21:14:40.1263919Z","execution_finish_time":"2025-10-17T21:14:42.6151256Z","parent_msg_id":"46446f59-c7fe-455f-9795-f0791959874e"},"text/plain":"StatementMeta(, 4825afcd-6c6c-4c32-a606-a141b2984f0a, 21, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Registered view: models\n✅ Registered view: dealers\n✅ Registered view: customers\n✅ Registered view: incentives\n✅ Registered view: inventory\n✅ Registered view: car_sales\n✅ All tables registered for SQL queries\n"]}],"execution_count":13,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9648b69e"},{"cell_type":"markdown","source":["### 13.0 Register Tables for SQL Queries\n","Create temporary views so Spark SQL can query the Delta tables."],"metadata":{},"id":"204eff2c"},{"cell_type":"markdown","source":["### 13.A Campaign Effectiveness\n","How much did the Azure Motors EV SUV campaign increase sales and revenue during the campaign months?"],"metadata":{},"id":"fff4222c"},{"cell_type":"code","source":["# Campaign impact: Azure Motors EV SUV uplift with dynamic interpretation\n","query = \"\"\"\n","SELECT\n","  CASE WHEN month IN ('2025-06','2025-07','2025-08','2025-09') THEN 'Campaign' ELSE 'Baseline' END AS period,\n","  SUM(units) AS total_units,\n","  SUM(revenue) AS total_revenue\n","FROM car_sales\n","WHERE brand = 'Azure Motors' AND body_type = 'EV SUV'\n","GROUP BY CASE WHEN month IN ('2025-06','2025-07','2025-08','2025-09') THEN 'Campaign' ELSE 'Baseline' END\n","ORDER BY period\n","\"\"\"\n","\n","# Execute query and display results\n","df = spark.sql(query)\n","display(df)\n","\n","# Calculate dynamic metrics from actual results\n","results = df.collect()\n","baseline = next((r for r in results if r['period'] == 'Baseline'), None)\n","campaign = next((r for r in results if r['period'] == 'Campaign'), None)\n","\n","if baseline and campaign:\n","    baseline_months = 20  # Total months minus 4 campaign months\n","    campaign_months = 4\n","    \n","    baseline_avg_units = baseline['total_units'] / baseline_months\n","    campaign_avg_units = campaign['total_units'] / campaign_months\n","    pct_increase = ((campaign_avg_units - baseline_avg_units) / baseline_avg_units) * 100\n","    \n","    baseline_per_unit = baseline['total_revenue'] / baseline['total_units']\n","    campaign_per_unit = campaign['total_revenue'] / campaign['total_units']\n","    margin_diff = baseline_per_unit - campaign_per_unit\n","    \n","    # Display dynamic interpretation\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"📊 CAMPAIGN PERFORMANCE ANALYSIS\")\n","    print(\"=\"*70)\n","    print(f\"\\n📈 VOLUME METRICS:\")\n","    print(f\"   • Baseline:  {baseline_avg_units:>10,.0f} units/month  (20 months)\")\n","    print(f\"   • Campaign:  {campaign_avg_units:>10,.0f} units/month  (Jun-Sep 2025)\")\n","    print(f\"   • Increase:  {pct_increase:>10.1f}% more units per month\")\n","    \n","    print(f\"\\n💰 REVENUE PER UNIT:\")\n","    print(f\"   • Baseline:  ${baseline_per_unit:>10,.2f} per unit\")\n","    print(f\"   • Campaign:  ${campaign_per_unit:>10,.2f} per unit\")\n","    print(f\"   • Margin:    ${margin_diff:>10,.2f} lower per unit (rebates + 1.9% APR)\")\n","    \n","    print(f\"\\n✅ STRATEGIC OUTCOME:\")\n","    if pct_increase > 15:\n","        print(f\"   🎯 Campaign SUCCESS! Gained {pct_increase:.1f}% more sales by trading\")\n","        print(f\"      ${margin_diff:.0f}/unit margin for significant volume growth.\")\n","        print(f\"   📌 Classic promotional trade-off: margin → market share\")\n","    else:\n","        print(f\"   ⚠️  Modest {pct_increase:.1f}% increase - evaluate ROI vs rebate cost\")\n","    print(\"=\"*70 + \"\\n\")\n","else:\n","    print(\"⚠️ Unable to calculate metrics - check if both Baseline and Campaign data exist\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e72cc242"},{"cell_type":"markdown","source":["### 13.B Regional Logistics Impact\n","How did logistics delays in the West/Pacific NW affect inventory levels and sales?"],"metadata":{},"id":"325a966c"},{"cell_type":"code","source":["# Regional logistics delay effect with dynamic interpretation\n","query = \"\"\"\n","SELECT\n","  region,\n","  month,\n","  SUM(incoming) AS total_incoming,\n","  SUM(on_hand) AS total_on_hand\n","FROM inventory\n","WHERE region IN ('West', 'Pacific NW') AND month IN ('2025-08', '2025-09')\n","GROUP BY region, month\n","ORDER BY region, month\n","\"\"\"\n","\n","# Execute query and display results\n","df = spark.sql(query)\n","display(df)\n","\n","# Compare with normal months for context\n","comparison_query = \"\"\"\n","SELECT\n","  region,\n","  AVG(incoming) AS avg_incoming_normal\n","FROM inventory\n","WHERE region IN ('West', 'Pacific NW') \n","  AND month NOT IN ('2025-08', '2025-09')\n","GROUP BY region\n","\"\"\"\n","normal_df = spark.sql(comparison_query)\n","normal_data = {r['region']: r['avg_incoming_normal'] for r in normal_df.collect()}\n","\n","# Analyze delay impact\n","results = df.collect()\n","if results:\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"🚚 LOGISTICS DELAY IMPACT ANALYSIS\")\n","    print(\"=\"*70)\n","    print(\"\\n📦 INCOMING INVENTORY COMPARISON:\")\n","    \n","    for row in results:\n","        region = row['region']\n","        month = row['month']\n","        incoming = row['total_incoming']\n","        normal_avg = normal_data.get(region, 0)\n","        \n","        if normal_avg > 0:\n","            pct_change = ((incoming - normal_avg) / normal_avg) * 100\n","            print(f\"\\n   {region} ({month}):\")\n","            print(f\"      • Incoming:        {incoming:>8,} units\")\n","            print(f\"      • Normal average:  {normal_avg:>8,.0f} units\")\n","            print(f\"      • Change:          {pct_change:>7.1f}% {'⬇️' if pct_change < 0 else '⬆️'}\")\n","    \n","    # Calculate total impact\n","    delay_months = df.filter(df.month.isin(['2025-08', '2025-09']))\n","    total_incoming_delay = delay_months.agg({'total_incoming': 'sum'}).collect()[0][0]\n","    \n","    print(f\"\\n📊 OVERALL IMPACT:\")\n","    print(f\"   • Total incoming (Aug-Sep):  {total_incoming_delay:,} units\")\n","    print(f\"   • Expected reduction: ~30% due to carrier constraints\")\n","    print(f\"   • Affected regions: West, Pacific NW\")\n","    \n","    print(f\"\\n⚠️  BUSINESS IMPLICATIONS:\")\n","    print(f\"   🔴 Potential stockouts in affected regions\")\n","    print(f\"   🔴 Extended lead times (+4 days estimated)\")\n","    print(f\"   🟡 May impact campaign fulfillment in these regions\")\n","    print(\"=\"*70 + \"\\n\")\n","else:\n","    print(\"⚠️ No data found for logistics delay period\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"36af3f11"},{"cell_type":"markdown","source":["### 13.C Dealer Performance\n","Which dealers had the highest sales, revenue, or profit?"],"metadata":{},"id":"35126705"},{"cell_type":"code","source":["# Top 10 dealers by profit with dynamic interpretation\n","import builtins  # Avoid conflict with PySpark's sum()\n","\n","query = \"\"\"\n","SELECT\n","  dealer_id,\n","  region,\n","  SUM(profit) AS total_profit,\n","  SUM(units) AS total_units,\n","  SUM(revenue) AS total_revenue\n","FROM car_sales\n","GROUP BY dealer_id, region\n","ORDER BY total_profit DESC\n","LIMIT 10\n","\"\"\"\n","\n","# Execute query and display results\n","df = spark.sql(query)\n","display(df)\n","\n","# Analyze top performers\n","results = df.collect()\n","if results:\n","    # Calculate network-wide averages for comparison\n","    avg_query = \"\"\"\n","    SELECT \n","        AVG(dealer_profit) AS avg_profit,\n","        AVG(dealer_units) AS avg_units\n","    FROM (\n","        SELECT dealer_id, SUM(profit) AS dealer_profit, SUM(units) AS dealer_units\n","        FROM car_sales\n","        GROUP BY dealer_id\n","    )\n","    \"\"\"\n","    avg_data = spark.sql(avg_query).collect()[0]\n","    network_avg_profit = avg_data['avg_profit']\n","    network_avg_units = avg_data['avg_units']\n","    \n","    top_dealer = results[0]\n","    total_top10_profit = builtins.sum(r['total_profit'] for r in results)\n","    \n","    print(\"\\n\" + \"=\"*70)\n","    print(\"🏆 TOP DEALER PERFORMANCE ANALYSIS\")\n","    print(\"=\"*70)\n","    \n","    print(f\"\\n🥇 TOP PERFORMER:\")\n","    print(f\"   • Dealer:          {top_dealer['dealer_id']}\")\n","    print(f\"   • Region:          {top_dealer['region']}\")\n","    print(f\"   • Total profit:    ${top_dealer['total_profit']:>12,.2f}\")\n","    print(f\"   • Units sold:      {top_dealer['total_units']:>12,}\")\n","    print(f\"   • Profit/unit:     ${top_dealer['total_profit']/top_dealer['total_units']:>12,.2f}\")\n","    \n","    vs_avg = ((top_dealer['total_profit'] - network_avg_profit) / network_avg_profit) * 100\n","    print(f\"   • vs Network avg:  {vs_avg:>11,.1f}% higher\")\n","    \n","    # Regional distribution\n","    region_counts = {}\n","    for r in results:\n","        region_counts[r['region']] = region_counts.get(r['region'], 0) + 1\n","    \n","    print(f\"\\n📍 REGIONAL DISTRIBUTION (Top 10):\")\n","    for region, count in sorted(region_counts.items(), key=lambda x: x[1], reverse=True):\n","        print(f\"   • {region:20s} {count} dealer(s)\")\n","    \n","    # Concentration analysis\n","    all_dealers_profit = spark.sql(\"SELECT SUM(profit) AS total FROM car_sales\").collect()[0]['total']\n","    concentration = (total_top10_profit / all_dealers_profit) * 100\n","    \n","    print(f\"\\n💼 PERFORMANCE CONCENTRATION:\")\n","    print(f\"   • Top 10 dealers: ${total_top10_profit:>12,.2f} profit\")\n","    print(f\"   • Network total:  ${all_dealers_profit:>12,.2f} profit\")\n","    print(f\"   • Concentration:  {concentration:>11.1f}% of total profit\")\n","    \n","    print(f\"\\n✅ INSIGHTS:\")\n","    if concentration > 10:\n","        print(f\"   ⚠️  High concentration ({concentration:.1f}%) - investigate success factors\")\n","        print(f\"   📌 Consider replicating top dealer strategies network-wide\")\n","    else:\n","        print(f\"   ✅ Balanced performance across dealer network\")\n","    print(\"=\"*70 + \"\\n\")\n","else:\n","    print(\"⚠️ No dealer data found\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"93b069a8"},{"cell_type":"markdown","source":["### 13.D Customer Segmentation\n","What are the demographic profiles of customers buying EVs vs. other body types?"],"metadata":{},"id":"0dc0a1b4"},{"cell_type":"code","source":["# Customer segmentation by income band with dynamic interpretation\n","import builtins  # Avoid conflict with PySpark's sum()\n","\n","query = \"\"\"\n","SELECT\n","  CASE\n","    WHEN annual_income < 50000 THEN 'Low'\n","    WHEN annual_income < 90000 THEN 'Medium'\n","    ELSE 'High'\n","  END AS income_band,\n","  COUNT(*) AS customer_count\n","FROM customers\n","GROUP BY CASE\n","    WHEN annual_income < 50000 THEN 'Low'\n","    WHEN annual_income < 90000 THEN 'Medium'\n","    ELSE 'High'\n","  END\n","ORDER BY customer_count DESC\n","\"\"\"\n","\n","# Execute query and display results\n","df = spark.sql(query)\n","display(df)\n","\n","# Analyze customer segmentation\n","results = df.collect()\n","if results:\n","    total_customers = builtins.sum(r['customer_count'] for r in results)\n","    \n","    # Get income stats\n","    income_stats = spark.sql(\"\"\"\n","        SELECT \n","            MIN(annual_income) AS min_income,\n","            MAX(annual_income) AS max_income,\n","            AVG(annual_income) AS avg_income,\n","            PERCENTILE_APPROX(annual_income, 0.5) AS median_income\n","        FROM customers\n","    \"\"\").collect()[0]\n","    \n","    print(\"\\n\" + \"=\"*70)\n","    print(\"👥 CUSTOMER SEGMENTATION ANALYSIS\")\n","    print(\"=\"*70)\n","    \n","    print(f\"\\n💰 INCOME DISTRIBUTION:\")\n","    for row in results:\n","        band = row['income_band']\n","        count = row['customer_count']\n","        pct = (count / total_customers) * 100\n","        \n","        # Define income range\n","        if band == 'Low':\n","            range_txt = \"< $50,000\"\n","        elif band == 'Medium':\n","            range_txt = \"$50,000 - $90,000\"\n","        else:\n","            range_txt = \"> $90,000\"\n","        \n","        bar = \"█\" * int(pct / 2)  # Visual bar chart\n","        print(f\"   {band:8s} ({range_txt:20s}): {count:>8,} ({pct:>5.1f}%) {bar}\")\n","    \n","    print(f\"\\n📊 INCOME STATISTICS:\")\n","    print(f\"   • Total customers:  {total_customers:>10,}\")\n","    print(f\"   • Average income:   ${income_stats['avg_income']:>10,.2f}\")\n","    print(f\"   • Median income:    ${income_stats['median_income']:>10,.2f}\")\n","    print(f\"   • Income range:     ${income_stats['min_income']:>10,.2f} - ${income_stats['max_income']:>10,.2f}\")\n","    \n","    # Age distribution\n","    age_stats = spark.sql(\"\"\"\n","        SELECT \n","            AVG(age) AS avg_age,\n","            MIN(age) AS min_age,\n","            MAX(age) AS max_age\n","        FROM customers\n","    \"\"\").collect()[0]\n","    \n","    print(f\"\\n👤 AGE PROFILE:\")\n","    print(f\"   • Average age:      {age_stats['avg_age']:>10.1f} years\")\n","    print(f\"   • Age range:        {age_stats['min_age']:>10.0f} - {age_stats['max_age']:.0f} years\")\n","    \n","    # Marketing insights\n","    high_income = next((r for r in results if r['income_band'] == 'High'), None)\n","    high_income_pct = (high_income['customer_count'] / total_customers * 100) if high_income else 0\n","    \n","    print(f\"\\n🎯 MARKETING INSIGHTS:\")\n","    if high_income_pct > 35:\n","        print(f\"   💎 Strong high-income segment ({high_income_pct:.1f}%)\")\n","        print(f\"   📌 Target for luxury/premium models & EV SUV campaign\")\n","    elif high_income_pct > 25:\n","        print(f\"   ✅ Balanced income distribution\")\n","        print(f\"   📌 Diversified product portfolio recommended\")\n","    else:\n","        print(f\"   💵 Price-sensitive market ({100-high_income_pct:.1f}% under $90K)\")\n","        print(f\"   📌 Focus on value propositions & financing options\")\n","    \n","    print(\"=\"*70 + \"\\n\")\n","else:\n","    print(\"⚠️ No customer data found\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"051610f7"},{"cell_type":"code","source":["# Spark validation helper (run after generation)\n","tables=['models','dealers','customers','incentives','inventory','car_sales']\n","for t in tables:\n","  try:\n","    cnt=spark.read.format('delta').load(f'Tables/{t}').count()\n","    print(f'{t:12s} -> {cnt:,} rows')\n","  except Exception as e:\n","    print(f'{t:12s} -> MISSING ({e})')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"00827c82-e21a-4066-bbe6-0d1aa33d7286","normalized_state":"finished","queued_time":"2025-10-18T13:44:36.5809543Z","session_start_time":null,"execution_start_time":"2025-10-18T13:44:36.5822299Z","execution_finish_time":"2025-10-18T13:44:57.319658Z","parent_msg_id":"1f004808-e53a-4c89-bbbc-0e4a6f95184f"},"text/plain":"StatementMeta(, 00827c82-e21a-4066-bbe6-0d1aa33d7286, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["models       -> 600 rows\ndealers      -> 1,200 rows\ncustomers    -> 1,000,000 rows\nincentives   -> 9,600 rows\ninventory    -> 17,280,000 rows\ncar_sales    -> 17,280,000 rows\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c8c95c21"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"719acf16-e0eb-4288-81b5-7aec243843c0"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"synapse_pyspark"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"45cb6aad-22fc-4eb1-bc15-6cdd41626774"}],"default_lakehouse":"45cb6aad-22fc-4eb1-bc15-6cdd41626774","default_lakehouse_name":"AgentCouncilLake","default_lakehouse_workspace_id":"276cfd05-ede1-4947-9c94-33d26f7c4095"}}},"nbformat":4,"nbformat_minor":5}